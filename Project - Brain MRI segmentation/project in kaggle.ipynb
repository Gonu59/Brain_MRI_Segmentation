{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "import Modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laboratory\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid import ImageGrid\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Global Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Path to all data\n",
    "DATA_PATH = \"lgg-mri-segmentation/kaggle_3m/\"\n",
    "\n",
    "# File path line length images for later sorting\n",
    "BASE_LEN = 89 # len(/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_ <-!!!43.tif)\n",
    "END_IMG_LEN = 4 # len(/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->.tif)\n",
    "END_MASK_LEN = 9 # (/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->_mask.tif)\n",
    "\n",
    "# img size\n",
    "IMG_SIZE = 512"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create A Dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not a dir: lgg-mri-segmentation/kaggle_3m\\data.csv\n",
      "This is not a dir: lgg-mri-segmentation/kaggle_3m\\README.md\n"
     ]
    },
    {
     "data": {
      "text/plain": "                           dirname  \\\n0  kaggle_3m\\TCGA_CS_4941_19960909   \n1  kaggle_3m\\TCGA_CS_4941_19960909   \n2  kaggle_3m\\TCGA_CS_4941_19960909   \n3  kaggle_3m\\TCGA_CS_4941_19960909   \n4  kaggle_3m\\TCGA_CS_4941_19960909   \n\n                                                path  \n0  lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...  \n1  lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...  \n2  lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...  \n3  lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...  \n4  lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirname</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data\n",
    "data_map = []\n",
    "for sub_dir_path in glob.glob(DATA_PATH+\"*\"):\n",
    "    if os.path.isdir(sub_dir_path):\n",
    "        dirname = sub_dir_path.split(\"/\")[-1]\n",
    "        for filename in os.listdir(sub_dir_path):\n",
    "            image_path = sub_dir_path + \"/\" + filename\n",
    "            data_map.extend([dirname, image_path])\n",
    "    else:\n",
    "        print(\"This is not a dir:\", sub_dir_path)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"dirname\" : data_map[::2],\n",
    "                  \"path\" : data_map[1::2]})\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the Image: lgg-mri-segmentation/kaggle_3m\\TCGA_CS_6665_20010817/TCGA_CS_6665_20010817_10.tif \n",
      "Path to the Mask: lgg-mri-segmentation/kaggle_3m\\TCGA_CS_6665_20010817/TCGA_CS_6665_20010817_11_mask.tif\n"
     ]
    }
   ],
   "source": [
    "# Masks/Not masks\n",
    "df_imgs = df[~df['path'].str.contains(\"mask\")]\n",
    "df_masks = df[df['path'].str.contains(\"mask\")]\n",
    "#\"\"\"\n",
    "# Data sorting\n",
    "imgs = sorted(df_imgs[\"path\"].values, key=lambda x : x[BASE_LEN:-END_IMG_LEN])\n",
    "masks = sorted(df_masks[\"path\"].values, key=lambda x : x[BASE_LEN:-END_MASK_LEN])\n",
    "\"\"\"\n",
    "# Data sorting\n",
    "imgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\n",
    "masks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n",
    "\"\"\"\n",
    "# Sorting check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   0,    1,    3,    5,    7,    9,   11,   13,   15,   17,\n",
      "            ...\n",
      "            7837, 7839, 7841, 7843, 7845, 7847, 7849, 7851, 7853, 7856],\n",
      "           dtype='int64', length=3929)\n"
     ]
    }
   ],
   "source": [
    "print(df_imgs.index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                              patient  \\\n0     kaggle_3m\\TCGA_CS_4941_19960909   \n1     kaggle_3m\\TCGA_CS_4941_19960909   \n2     kaggle_3m\\TCGA_CS_4941_19960909   \n3     kaggle_3m\\TCGA_CS_4941_19960909   \n4     kaggle_3m\\TCGA_CS_4941_19960909   \n...                               ...   \n3924  kaggle_3m\\TCGA_HT_A61B_19991127   \n3925  kaggle_3m\\TCGA_HT_A61B_19991127   \n3926  kaggle_3m\\TCGA_HT_A61B_19991127   \n3927  kaggle_3m\\TCGA_HT_A61B_19991127   \n3928  kaggle_3m\\TCGA_HT_A61B_19991127   \n\n                                             image_path  \\\n0     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...   \n1     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...   \n2     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...   \n3     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...   \n4     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...   \n...                                                 ...   \n3924  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...   \n3925  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...   \n3926  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...   \n3927  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...   \n3928  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...   \n\n                                              mask_path  diagnosis  \n0     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...          0  \n1     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...          1  \n2     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...          1  \n3     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...          1  \n4     lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...          1  \n...                                                 ...        ...  \n3924  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...          0  \n3925  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...          0  \n3926  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...          0  \n3927  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...          0  \n3928  lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...          0  \n\n[3929 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kaggle_3m\\TCGA_CS_4941_19960909</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_CS_4941_19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3924</th>\n      <td>kaggle_3m\\TCGA_HT_A61B_19991127</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3925</th>\n      <td>kaggle_3m\\TCGA_HT_A61B_19991127</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3926</th>\n      <td>kaggle_3m\\TCGA_HT_A61B_19991127</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3927</th>\n      <td>kaggle_3m\\TCGA_HT_A61B_19991127</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3928</th>\n      <td>kaggle_3m\\TCGA_HT_A61B_19991127</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>lgg-mri-segmentation/kaggle_3m\\TCGA_HT_A61B_19...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3929 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final dataframe\n",
    "df = pd.DataFrame({\"patient\": df_imgs.dirname.values,\n",
    "                       \"image_path\": imgs,\n",
    "                   \"mask_path\": masks})\n",
    "\n",
    "\n",
    "# Adding A/B column for diagnosis\n",
    "def positiv_negativ_diagnosis(mask_path):\n",
    "    value = np.max(cv2.imread(mask_path))\n",
    "    if value > 0 : return 1\n",
    "    else: return 0\n",
    "\n",
    "df[\"diagnosis\"] = df[\"mask_path\"].apply(lambda m: positiv_negativ_diagnosis(m))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DataGenerator and Data Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid import ImageGrid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class BrainMriDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.df.iloc[idx, 1])\n",
    "        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n",
    "\n",
    "        augmented = self.transforms(image=image,\n",
    "                                    mask=mask)\n",
    "\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "        # unnormilize mask\n",
    "        #mask = torch.clamp(mask.float(), min=0, max=1)\n",
    "        #mask = torch.ceil(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laboratory\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\albumentations\\imgaug\\transforms.py:165: FutureWarning: This augmentation is deprecated. Please use Emboss instead\n",
      "  warnings.warn(\"This augmentation is deprecated. Please use Emboss instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = 128#256\n",
    "\n",
    "strong_transforms = A.Compose([\n",
    "    A.RandomResizedCrop(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "\n",
    "    # Pixels\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomGamma(p=0.25),\n",
    "    A.IAAEmboss(p=0.25),\n",
    "    A.Blur(p=0.01, blur_limit = 3),\n",
    "\n",
    "    # Affine\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
    "    ], p=0.8),\n",
    "\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    #https://albumentations.readthedocs.io/en/latest/api/pytorch.html?highlight=ToTensor#albumentations.pytorch.transforms.ToTensor\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.Resize(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "\n",
    "\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensor(),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data on train val test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3005, 4) \n",
      "Val: (393, 4) \n",
      "Test: (531, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split df into train_df and val_df\n",
    "train_df, val_df = train_test_split(df, stratify=df.diagnosis, test_size=0.1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "# Split train_df into train_df and test_df\n",
    "train_df, test_df = train_test_split(train_df, stratify=train_df.diagnosis, test_size=0.15)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "#train_df = train_df[:1000]\n",
    "print(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# train\n",
    "train_dataset = BrainMriDataset(df=train_df, transforms=transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=26, num_workers=0, shuffle=True)\n",
    "\n",
    "# val\n",
    "val_dataset = BrainMriDataset(df=val_df, transforms=transforms)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=26, num_workers=0, shuffle=True)\n",
    "\n",
    "#test\n",
    "test_dataset = BrainMriDataset(df=test_df, transforms=transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=26, num_workers=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "U-Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_down1 = double_conv(3, 64)\n",
    "        self.conv_down2 = double_conv(64, 128)\n",
    "        self.conv_down3 = double_conv(128, 256)\n",
    "        self.conv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = double_conv(256 + 512, 256)\n",
    "        self.conv_up2 = double_conv(128 + 256, 128)\n",
    "        self.conv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.last_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Batch - 1d tensor.  N_channels - 1d tensor, IMG_SIZE - 2d tensor.\n",
    "        # Example: x.shape >>> (10, 3, 256, 256).\n",
    "\n",
    "        conv1 = self.conv_down1(x)  # <- BATCH, 3, IMG_SIZE  -> BATCH, 64, IMG_SIZE..\n",
    "        x = self.maxpool(conv1)     # <- BATCH, 64, IMG_SIZE -> BATCH, 64, IMG_SIZE 2x down.\n",
    "        conv2 = self.conv_down2(x)  # <- BATCH, 64, IMG_SIZE -> BATCH,128, IMG_SIZE.\n",
    "        x = self.maxpool(conv2)     # <- BATCH, 128, IMG_SIZE -> BATCH, 128, IMG_SIZE 2x down.\n",
    "        conv3 = self.conv_down3(x)  # <- BATCH, 128, IMG_SIZE -> BATCH, 256, IMG_SIZE.\n",
    "        x = self.maxpool(conv3)     # <- BATCH, 256, IMG_SIZE -> BATCH, 256, IMG_SIZE 2x down.\n",
    "        x = self.conv_down4(x)      # <- BATCH, 256, IMG_SIZE -> BATCH, 512, IMG_SIZE.\n",
    "        x = self.upsample(x)        # <- BATCH, 512, IMG_SIZE -> BATCH, 512, IMG_SIZE 2x up.\n",
    "\n",
    "        #(Below the same)                                 N this       ==        N this.  Because the first N is upsampled.\n",
    "        x = torch.cat([x, conv3], dim=1) # <- BATCH, 512, IMG_SIZE & BATCH, 256, IMG_SIZE--> BATCH, 768, IMG_SIZE.\n",
    "\n",
    "        x = self.conv_up3(x) #  <- BATCH, 768, IMG_SIZE --> BATCH, 256, IMG_SIZE.\n",
    "        x = self.upsample(x)  #  <- BATCH, 256, IMG_SIZE -> BATCH,  256, IMG_SIZE 2x up.\n",
    "        x = torch.cat([x, conv2], dim=1) # <- BATCH, 256,IMG_SIZE & BATCH, 128, IMG_SIZE --> BATCH, 384, IMG_SIZE.\n",
    "\n",
    "        x = self.conv_up2(x) # <- BATCH, 384, IMG_SIZE --> BATCH, 128 IMG_SIZE.\n",
    "        x = self.upsample(x)   # <- BATCH, 128, IMG_SIZE --> BATCH, 128, IMG_SIZE 2x up.\n",
    "        x = torch.cat([x, conv1], dim=1) # <- BATCH, 128, IMG_SIZE & BATCH, 64, IMG_SIZE --> BATCH, 192, IMG_SIZE.\n",
    "\n",
    "        x = self.conv_up1(x) # <- BATCH, 128, IMG_SIZE --> BATCH, 64, IMG_SIZE.\n",
    "\n",
    "        out = self.last_conv(x) # <- BATCH, 64, IMG_SIZE --> BATCH, n_classes, IMG_SIZE.\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "unet = UNet(n_classes=1).to(device)\n",
    "output = unet(torch.randn(1,3,256,256).to(device))\n",
    "print(\"\",output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dice-coefficient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1637)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dice_coef_metric(inputs, target):\n",
    "    intersection = 2.0 * (target * inputs).sum()\n",
    "    union = target.sum() + inputs.sum()\n",
    "    if target.sum() == 0 and inputs.sum() == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "# Metric check\n",
    "dice_coef_metric(np.array([0., 0.9]), np.array([0., 1]))\n",
    "\n",
    "def dice_coef_loss(inputs, target):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
    "    union = target.sum() + inputs.sum() + smooth\n",
    "\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "def bce_dice_loss(inputs, target):\n",
    "    dicescore = dice_coef_loss(inputs, target)\n",
    "    bcescore = nn.BCELoss()\n",
    "    bceloss = bcescore(inputs, target)\n",
    "\n",
    "    return bceloss + dicescore\n",
    "\n",
    "# loss check\n",
    "bce_dice_loss(torch.tensor([0.7, 1., 1.]),\n",
    "              torch.tensor([1.,1.,1.]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):\n",
    "\n",
    "    print(model_name)\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "\n",
    "        losses = []\n",
    "        train_iou = []\n",
    "\n",
    "        if lr_scheduler:\n",
    "\n",
    "            warmup_factor = 1.0 / 100\n",
    "            warmup_iters = min(100, len(train_loader) - 1)\n",
    "            lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "\n",
    "        for i_step, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "\n",
    "            loss = train_loss(outputs, target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            train_iou.append(train_dice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "        #torch.save(model.state_dict(), f'{model_name}_{str(epoch)}_epoch.pt')\n",
    "        val_mean_iou = compute_iou(model, val_loader)\n",
    "\n",
    "        loss_history.append(np.array(losses).mean())\n",
    "        train_history.append(np.array(train_iou).mean())\n",
    "        val_history.append(val_mean_iou)\n",
    "\n",
    "        print(\"Epoch [%d]\" % (epoch))\n",
    "        print(\"Mean loss on train:\", np.array(losses).mean(),\n",
    "              \"\\nMean DICE on train:\", np.array(train_iou).mean(),\n",
    "              \"\\nMean DICE on validation:\", val_mean_iou)\n",
    "\n",
    "    return loss_history, train_history, val_history\n",
    "\n",
    "\n",
    "def compute_iou(model, loader, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "\n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    #model.eval()\n",
    "    valloss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i_step, (data, target) in enumerate(loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            #prediction = model(x_gpu)\n",
    "\n",
    "            outputs = model(data)\n",
    "           # print(\"val_output:\", outputs.shape)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "\n",
    "            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "            valloss += picloss\n",
    "\n",
    "        #print(\"Threshold:  \" + str(threshold) + \"  Validation DICE score:\", valloss / i_step)\n",
    "\n",
    "    return valloss / i_step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "unet_optimizer = torch.optim.Adamax(unet.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# lr_scheduler\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla_UNet\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ToTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10548\\3244727404.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mi_step\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m             \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    436\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    474\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 475\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    476\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    477\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10548\\959230022.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         augmented = self.transforms(image=image,\n\u001B[1;32m---> 15\u001B[1;33m                                     mask=mask)\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maugmented\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'image'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\albumentations\\core\\composition.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    190\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 191\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mforce_apply\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mforce_apply\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    192\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    193\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcheck_each_transform\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'ToTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_ep = 10\n",
    "# Train UNet\n",
    "unet_lh, unet_th, unet_vh = train_model(\"Vanilla_UNet\", unet, train_dataloader, val_dataloader, bce_dice_loss, unet_optimizer, False, 20)\n",
    "\n",
    "# Train FPN\n",
    "#fpn_lh, fpn_th, fpn_vh = train_model(\"FPN\", fpn, train_dataloader, val_dataloader, bce_dice_loss, fpn_optimizer, False, 20)#\n",
    "\n",
    "# Train ResNeXt50\n",
    "#rx50_lh, rx50_th, rx50_vh = train_model(\"ResNeXt50\",  train_dataloader, val_dataloader, bce_dice_loss, False, num_ep)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def plot_model_history(model_name,\n",
    "                        train_history, val_history,\n",
    "                        num_epochs):\n",
    "\n",
    "    x = np.arange(num_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n",
    "    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n",
    "\n",
    "    plt.title(f\"{model_name}\", fontsize=15)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel(\"Epoch\", fontsize=15)\n",
    "    plt.ylabel(\"DICE\", fontsize=15)\n",
    "\n",
    "    fn = str(int(time.time())) + \".png\"\n",
    "    plt.show()\n",
    "    #plt.savefig(fn, bbox_inches='tight', pad_inches=0.2)\n",
    "    #plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unet_th' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10548\\132013333.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mplot_model_history\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Vanilla UNet\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munet_th\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munet_vh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m20\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;31m#plot_model_history(\"FPN\", fpn_th, fpn_vh, 20)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#plot_model_history(\"UNet with ResNeXt50 backbone\", rx50_th, rx50_vh, num_ep)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'unet_th' is not defined"
     ]
    }
   ],
   "source": [
    "#plot_model_history(\"Vanilla UNet\", unet_th, unet_vh, 20)\n",
    "#plot_model_history(\"FPN\", fpn_th, fpn_vh, 20)\n",
    "#plot_model_history(\"UNet with ResNeXt50 backbone\", rx50_th, rx50_vh, num_ep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "random test sampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unet_th' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10548\\1474941785.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m# pred\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m255.\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munet_th\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpred\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'unet_th' is not defined"
     ]
    }
   ],
   "source": [
    "# image\n",
    "test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(1).values[0]\n",
    "image = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n",
    "\n",
    "#mask\n",
    "mask = cv2.resize(cv2.imread(test_sample[2]), (128, 128))\n",
    "\n",
    "# pred\n",
    "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\n",
    "pred = unet_th(pred.to(device))\n",
    "pred = pred.detach().cpu().numpy()[0,0,:,:]\n",
    "\n",
    "# pred with tshd\n",
    "pred_t = np.copy(pred)\n",
    "pred_t[np.nonzero(pred_t < 0.3)] = 0.0\n",
    "pred_t[np.nonzero(pred_t >= 0.3)] = 255.#1.0\n",
    "pred_t = pred_t.astype(\"uint8\")\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n",
    "\n",
    "ax[0, 0].imshow(image)\n",
    "ax[0, 0].set_title(\"image\")\n",
    "ax[0, 1].imshow(mask)\n",
    "ax[0, 1].set_title(\"mask\")\n",
    "ax[1, 0].imshow(pred)\n",
    "ax[1, 0].set_title(\"prediction\")\n",
    "ax[1, 1].imshow(pred_t)\n",
    "ax[1, 1].set_title(\"prediction with threshold\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_samples = test_df[test_df[\"diagnosis\"] == 1].sample(105).values\n",
    "\n",
    "\n",
    "def batch_preds_overlap(model, samples):\n",
    "    \"\"\"\n",
    "    Computes prediction on the dataset\n",
    "\n",
    "    Returns: list with images overlapping with predictions\n",
    "\n",
    "    \"\"\"\n",
    "    prediction_overlap = []\n",
    "    #model.eval():\n",
    "    for test_sample in samples:\n",
    "\n",
    "         # sample\n",
    "        image = cv2.resize(cv2.imread(test_sample[1]),(128, 128))\n",
    "        image =  image / 255.\n",
    "\n",
    "        # gt\n",
    "        ground_truth = cv2.resize(cv2.imread(test_sample[2], 0), (128, 128)).astype(\"uint8\")\n",
    "\n",
    "        # pred\n",
    "        prediction = torch.tensor(image).unsqueeze(0).permute(0,3,1,2)\n",
    "        prediction = model(prediction.to(device).float())\n",
    "        prediction = prediction.detach().cpu().numpy()[0,0,:,:]\n",
    "\n",
    "        prediction[np.nonzero(prediction < 0.3)] = 0.0\n",
    "        prediction[np.nonzero(prediction >= 0.3)] = 255.#1.0\n",
    "        prediction = prediction.astype(\"uint8\")\n",
    "\n",
    "        # overlap\n",
    "        original_img = cv2.resize(cv2.imread(test_sample[1]),(128, 128))\n",
    "\n",
    "        _, thresh_gt = cv2.threshold(ground_truth, 127, 255, 0)\n",
    "        _, thresh_p = cv2.threshold(prediction, 127, 255, 0)\n",
    "        contours_gt, _ = cv2.findContours(thresh_gt, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_p, _ = cv2.findContours(thresh_p, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        overlap_img = cv2.drawContours(original_img, contours_gt, 0, (0, 255, 0), 1)\n",
    "        overlap_img = cv2.drawContours(overlap_img, contours_p, 0, (255,36,0), 1)#255,0,0\n",
    "        prediction_overlap.append(overlap_img)\n",
    "\n",
    "    return prediction_overlap\n",
    "\n",
    "\n",
    "#prediction_overlap_u = batch_preds_overlap(unet, test_samples)\n",
    "#prediction_overlap_f = batch_preds_overlap(fpn, test_samples)\n",
    "prediction_overlap_r = batch_preds_overlap(rx50, test_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}